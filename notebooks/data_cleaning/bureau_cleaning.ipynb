{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7634829",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "CURRENT_DIRECTORY_NOTEBOOK = None\n",
    "\n",
    "\n",
    "def intitate_notebook():\n",
    "    load_dotenv()\n",
    "    global CURRENT_DIRECTORY_NOTEBOOK\n",
    "    if CURRENT_DIRECTORY_NOTEBOOK is None:\n",
    "        os.chdir(os.getenv(\"PROJECT_BASE_PATH\"))\n",
    "        CURRENT_DIRECTORY_NOTEBOOK = Path(os.getcwd())\n",
    "        print(\"Current directory for notebook: \", CURRENT_DIRECTORY_NOTEBOOK)\n",
    "    else:\n",
    "        print(\n",
    "            \"Current directory for notebook is already set: \",\n",
    "            CURRENT_DIRECTORY_NOTEBOOK,\n",
    "        )\n",
    "\n",
    "\n",
    "intitate_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5777fb4",
   "metadata": {},
   "source": [
    "#### Feature Engineering - Code\n",
    "O - https://chatgpt.com/c/683b0134-e464-800c-b614-ccc268735823"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412bcdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import (\n",
    "    count,\n",
    "    sum as Fsum,\n",
    "    avg,\n",
    "    max as Fmax,\n",
    "    min as Fmin,\n",
    "    stddev,\n",
    "    broadcast,\n",
    "    when,\n",
    "    col,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf3e205",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession.builder.appName(\"PostgresETL\")\n",
    "    .config(\"spark.jars\", \"setup_files/postgresql-42.7.5.jar\")\n",
    "    .config(\"spark.driver.memory\", \"4g\")\n",
    "    .config(\"spark.executor.memory\", \"2g\")\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"100\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "\n",
    "username = \"data_source_user\"\n",
    "password = \"data_source_user_password\"\n",
    "host = \"172.17.0.1\"\n",
    "port = \"5435\"\n",
    "database = \"data_source_db\"\n",
    "\n",
    "\n",
    "jdbc_url = f\"jdbc:postgresql://{host}:{port}/{database}\"\n",
    "properties = {\"user\": username, \"password\": password, \"driver\": \"org.postgresql.Driver\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bb4271",
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau_df = spark.read.option(\"failFast\", \"true\").jdbc(\n",
    "    url=jdbc_url, table=\"bureau\", properties=properties\n",
    ")\n",
    "\n",
    "bureau_balance_df = spark.read.option(\"failFast\", \"true\").jdbc(\n",
    "    url=jdbc_url, table=\"bureau_balance\", properties=properties\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7715ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bureau_balance_features(\n",
    "    bureau_balance: DataFrame, bureau: DataFrame, target_shuffle_partitions: int = None\n",
    ") -> DataFrame:\n",
    "    \"\"\"\n",
    "    5. BUREAU BALANCE FEATURES\n",
    "    Join bureau_balance with bureau to get sk_id_curr,\n",
    "    then aggregate bureau_balance features grouped by sk_id_curr.\n",
    "\n",
    "    1) Project-down to only the columns we need from both tables.\n",
    "    2) Broadcast 'bureau' (which is usually much smaller) to avoid a full shuffle join.\n",
    "    3) Repartition by 'sk_id_curr' before doing the groupBy so that the per-group shuffle is minimized.\n",
    "    4) Optionally, reduce spark.sql.shuffle.partitions if your cluster is small.\n",
    "\n",
    "    Args:\n",
    "      bureau_balance: DataFrame with columns [sk_id_bureau, months_balance, status, ...other columns...]\n",
    "      bureau:         DataFrame with columns [sk_id_bureau, sk_id_curr, ...other columns...]\n",
    "      target_shuffle_partitions: if set, we will override spark.sql.shuffle.partitions to this value.\n",
    "\n",
    "    Returns:\n",
    "      DataFrame with one row per sk_id_curr and all the aggregated bureau_balance features.\n",
    "    \"\"\"\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 1) Project only the needed columns from each DataFrame\n",
    "    # -------------------------------------------------------------------------\n",
    "    bb_small = bureau_balance.select(\"sk_id_bureau\", \"months_balance\", \"status\")\n",
    "    bureau_balance = bureau_balance.repartition(\"sk_id_bureau\")\n",
    "    b_small = bureau.select(\"sk_id_bureau\", \"sk_id_curr\")\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 2) Broadcast-join: if 'bureau' is much smaller than 'bureau_balance',\n",
    "    #    we avoid a large shuffle on sk_id_bureau\n",
    "    # -------------------------------------------------------------------------\n",
    "    joined = bb_small.join(broadcast(b_small), on=\"sk_id_bureau\", how=\"left\")\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 3) Repartition by the grouping key to keep each sk_id_curr on one partition\n",
    "    # -------------------------------------------------------------------------\n",
    "    repartitioned = joined.repartition(\"sk_id_curr\")\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 4) Define all of our aggregate expressions in one go.\n",
    "    #    We compute basic counts, min/max of months_balance,\n",
    "    #    status-counts, DPD‐related counts, and 12‐month‐window counts.\n",
    "    # -------------------------------------------------------------------------\n",
    "    agg_exprs = [\n",
    "        # Basic counts and min/max:\n",
    "        F.count(\"months_balance\").alias(\"bureau_balance_months_count\"),\n",
    "        F.min(\"months_balance\").alias(\"bureau_balance_months_min\"),\n",
    "        F.max(\"months_balance\").alias(\"bureau_balance_months_max\"),\n",
    "        (F.max(\"months_balance\") - F.min(\"months_balance\")).alias(\n",
    "            \"bureau_balance_history_length\"\n",
    "        ),\n",
    "        # Status‐by‐status counts (0,1,2,3,4,5,C,X):\n",
    "        F.sum(when(col(\"status\") == \"0\", 1).otherwise(0)).alias(\n",
    "            \"bureau_status_0_count\"\n",
    "        ),\n",
    "        F.sum(when(col(\"status\") == \"1\", 1).otherwise(0)).alias(\n",
    "            \"bureau_status_1_count\"\n",
    "        ),\n",
    "        F.sum(when(col(\"status\") == \"2\", 1).otherwise(0)).alias(\n",
    "            \"bureau_status_2_count\"\n",
    "        ),\n",
    "        F.sum(when(col(\"status\") == \"3\", 1).otherwise(0)).alias(\n",
    "            \"bureau_status_3_count\"\n",
    "        ),\n",
    "        F.sum(when(col(\"status\") == \"4\", 1).otherwise(0)).alias(\n",
    "            \"bureau_status_4_count\"\n",
    "        ),\n",
    "        F.sum(when(col(\"status\") == \"5\", 1).otherwise(0)).alias(\n",
    "            \"bureau_status_5_count\"\n",
    "        ),\n",
    "        F.sum(when(col(\"status\") == \"C\", 1).otherwise(0)).alias(\n",
    "            \"bureau_status_c_count\"\n",
    "        ),\n",
    "        F.sum(when(col(\"status\") == \"X\", 1).otherwise(0)).alias(\n",
    "            \"bureau_status_x_count\"\n",
    "        ),\n",
    "        # Total number of status records (for ratio denominator)\n",
    "        F.count(\"status\").alias(\"bureau_status_total_count\"),\n",
    "        # DPD‐related counts (DPD = days past due)\n",
    "        F.sum(when(col(\"status\").isin(\"1\", \"2\", \"3\", \"4\", \"5\"), 1).otherwise(0)).alias(\n",
    "            \"bureau_dpd_count\"\n",
    "        ),\n",
    "        F.sum(when(col(\"status\").isin(\"2\", \"3\", \"4\", \"5\"), 1).otherwise(0)).alias(\n",
    "            \"bureau_dpd_30_count\"\n",
    "        ),\n",
    "        F.sum(when(col(\"status\").isin(\"3\", \"4\", \"5\"), 1).otherwise(0)).alias(\n",
    "            \"bureau_dpd_60_count\"\n",
    "        ),\n",
    "        F.sum(when(col(\"status\").isin(\"4\", \"5\"), 1).otherwise(0)).alias(\n",
    "            \"bureau_dpd_90_count\"\n",
    "        ),\n",
    "        F.sum(when(col(\"status\") == \"5\", 1).otherwise(0)).alias(\n",
    "            \"bureau_severe_dpd_count\"\n",
    "        ),\n",
    "        # “Recent 12 months” behavior (months_balance >= -12):\n",
    "        F.sum(\n",
    "            when(\n",
    "                (col(\"months_balance\") >= -12)\n",
    "                & col(\"status\").isin(\"1\", \"2\", \"3\", \"4\", \"5\"),\n",
    "                1,\n",
    "            ).otherwise(0)\n",
    "        ).alias(\"bureau_recent_dpd_count_12m\"),\n",
    "        F.sum(\n",
    "            when((col(\"months_balance\") >= -12) & (col(\"status\") == \"5\"), 1).otherwise(\n",
    "                0\n",
    "            )\n",
    "        ).alias(\"bureau_recent_severe_dpd_12m\"),\n",
    "        F.sum(\n",
    "            when((col(\"months_balance\") >= -12) & (col(\"status\") == \"C\"), 1).otherwise(\n",
    "                0\n",
    "            )\n",
    "        ).alias(\"bureau_recent_closed_12m\"),\n",
    "    ]\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 5) Perform the groupBy‐aggregation\n",
    "    # -------------------------------------------------------------------------\n",
    "    grouped = repartitioned.groupBy(\"sk_id_curr\").agg(*agg_exprs)\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 6) Finally, compute the ratio columns.  We do null‐safe division in case\n",
    "    #    bureau_status_total_count is zero (we cast to double by dividing by a literal 1.0).\n",
    "    # -------------------------------------------------------------------------\n",
    "    # You could also use:\n",
    "    #   F.when(col(\"bureau_status_total_count\") > 0,\n",
    "    #          col(\"bureau_dpd_count\") / col(\"bureau_status_total_count\")\n",
    "    #   ).otherwise(0.0)\n",
    "    # if you prefer to explicitly handle divide‐by‐zero.\n",
    "    #\n",
    "    results = (\n",
    "        grouped.withColumn(\n",
    "            \"bureau_dpd_ratio\",\n",
    "            col(\"bureau_dpd_count\") / (col(\"bureau_status_total_count\") + F.lit(0.0)),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"bureau_dpd_30_ratio\",\n",
    "            col(\"bureau_dpd_30_count\")\n",
    "            / (col(\"bureau_status_total_count\") + F.lit(0.0)),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"bureau_dpd_60_ratio\",\n",
    "            col(\"bureau_dpd_60_count\")\n",
    "            / (col(\"bureau_status_total_count\") + F.lit(0.0)),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"bureau_dpd_90_ratio\",\n",
    "            col(\"bureau_dpd_90_count\")\n",
    "            / (col(\"bureau_status_total_count\") + F.lit(0.0)),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"bureau_severe_dpd_ratio\",\n",
    "            col(\"bureau_severe_dpd_count\")\n",
    "            / (col(\"bureau_status_total_count\") + F.lit(0.0)),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7cc3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bureau_basic_counts_features(bureau: DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "    1. BASIC AGGREGATION FEATURES: Credit counts and credit type distribution\n",
    "    \"\"\"\n",
    "    credit_active_counts = [\n",
    "        (\"active\", \"bureau_active_count\"),\n",
    "        (\"closed\", \"bureau_closed_count\"),\n",
    "        (\"sold\", \"bureau_sold_count\"),\n",
    "        (\"bad debt\", \"bureau_bad_debt_count\"),\n",
    "    ]\n",
    "    credit_type_counts = [\n",
    "        (\"Consumer credit\", \"bureau_consumer_loan_count\"),\n",
    "        (\"Credit card\", \"bureau_credit_card_count\"),\n",
    "        (\"Mortgage\", \"bureau_mortgage_count\"),\n",
    "        (\"Car loan\", \"bureau_car_loan_count\"),\n",
    "        (\"Microloan\", \"bureau_microloan_count\"),\n",
    "    ]\n",
    "\n",
    "    agg_exprs = [count(\"sk_id_bureau\").alias(\"bureau_credit_count\")]\n",
    "\n",
    "    # Add credit_active conditional counts\n",
    "    for val, alias_name in credit_active_counts:\n",
    "        agg_exprs.append(\n",
    "            Fsum(when(col(\"credit_active\") == val, 1).otherwise(0)).alias(alias_name)\n",
    "        )\n",
    "    # Add credit_type conditional counts\n",
    "    for val, alias_name in credit_type_counts:\n",
    "        agg_exprs.append(\n",
    "            Fsum(when(col(\"credit_type\") == val, 1).otherwise(0)).alias(alias_name)\n",
    "        )\n",
    "\n",
    "    return bureau.groupBy(\"sk_id_curr\").agg(*agg_exprs)\n",
    "\n",
    "\n",
    "def bureau_amount_based_features(bureau: DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "    2. AMOUNT-BASED FEATURES: sums, means, ratios on credit, debt, limits, overdue\n",
    "    \"\"\"\n",
    "    df = bureau\n",
    "\n",
    "    # Aggregations on AMT_CREDIT_SUM and related\n",
    "    agg_exprs = [\n",
    "        Fsum(\"amt_credit_sum\").alias(\"bureau_amt_credit_sum_total\"),\n",
    "        avg(\"amt_credit_sum\").alias(\"bureau_amt_credit_sum_mean\"),\n",
    "        Fmax(\"amt_credit_sum\").alias(\"bureau_amt_credit_sum_max\"),\n",
    "        Fmin(\"amt_credit_sum\").alias(\"bureau_amt_credit_sum_min\"),\n",
    "        stddev(\"amt_credit_sum\").alias(\"bureau_amt_credit_sum_std\"),\n",
    "        Fsum(\"amt_credit_sum_debt\").alias(\"bureau_amt_credit_sum_debt_total\"),\n",
    "        avg(\"amt_credit_sum_debt\").alias(\"bureau_amt_credit_sum_debt_mean\"),\n",
    "        Fmax(\"amt_credit_sum_debt\").alias(\"bureau_amt_credit_sum_debt_max\"),\n",
    "        # Debt to credit ratio (safe divide)\n",
    "        (Fsum(\"amt_credit_sum_debt\") / Fsum(\"amt_credit_sum\")).alias(\n",
    "            \"bureau_debt_credit_ratio\"\n",
    "        ),\n",
    "        Fsum(\"amt_credit_sum_limit\").alias(\"bureau_amt_credit_sum_limit_total\"),\n",
    "        avg(\"amt_credit_sum_limit\").alias(\"bureau_amt_credit_sum_limit_mean\"),\n",
    "        # Credit utilization ratio (debt / limit)\n",
    "        (Fsum(\"amt_credit_sum_debt\") / Fsum(\"amt_credit_sum_limit\")).alias(\n",
    "            \"bureau_limit_utilization_ratio\"\n",
    "        ),\n",
    "        Fsum(\"amt_credit_sum_overdue\").alias(\"bureau_amt_credit_sum_overdue_total\"),\n",
    "        avg(\"amt_credit_sum_overdue\").alias(\"bureau_amt_credit_sum_overdue_mean\"),\n",
    "        Fmax(\"amt_credit_max_overdue\").alias(\"bureau_amt_credit_max_overdue_max\"),\n",
    "        # Has overdue flag: max of indicator if overdue > 0\n",
    "        Fmax(when(col(\"amt_credit_sum_overdue\") > 0, 1).otherwise(0)).alias(\n",
    "            \"bureau_has_overdue_flag\"\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    return df.groupBy(\"sk_id_curr\").agg(*agg_exprs)\n",
    "\n",
    "\n",
    "def bureau_time_based_features(bureau: DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "    3. TIME-BASED FEATURES: credit age, end date, update recency, recent credit counts\n",
    "    \"\"\"\n",
    "    df = bureau\n",
    "\n",
    "    # Recent credit counts in last 1 and 2 years (-365 and -730 days)\n",
    "    recent_1y = Fsum(when(col(\"days_credit\") >= -365, 1).otherwise(0)).alias(\n",
    "        \"bureau_recent_credit_count_1y\"\n",
    "    )\n",
    "    recent_2y = Fsum(when(col(\"days_credit\") >= -730, 1).otherwise(0)).alias(\n",
    "        \"bureau_recent_credit_count_2y\"\n",
    "    )\n",
    "\n",
    "    agg_exprs = [\n",
    "        Fmin(\"days_credit\").alias(\"bureau_days_credit_min\"),\n",
    "        Fmax(\"days_credit\").alias(\"bureau_days_credit_max\"),\n",
    "        avg(\"days_credit\").alias(\"bureau_days_credit_mean\"),\n",
    "        (Fmax(\"days_credit\") - Fmin(\"days_credit\")).alias(\n",
    "            \"bureau_credit_history_length\"\n",
    "        ),\n",
    "        recent_1y,\n",
    "        recent_2y,\n",
    "        Fmin(\"days_credit_enddate\").alias(\"bureau_days_credit_enddate_min\"),\n",
    "        Fmax(\"days_credit_enddate\").alias(\"bureau_days_credit_enddate_max\"),\n",
    "        avg(\"days_credit_enddate\").alias(\"bureau_days_credit_enddate_mean\"),\n",
    "        Fmin(\"days_credit_update\").alias(\"bureau_days_credit_update_min\"),\n",
    "        Fmax(\"days_credit_update\").alias(\"bureau_days_credit_update_max\"),\n",
    "        avg(\"days_credit_update\").alias(\"bureau_days_credit_update_mean\"),\n",
    "    ]\n",
    "\n",
    "    return df.groupBy(\"sk_id_curr\").agg(*agg_exprs)\n",
    "\n",
    "\n",
    "def bureau_delinquency_features(bureau: DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "    4. DELINQUENCY FEATURES: days overdue, dpd counts, credit prolongations\n",
    "    \"\"\"\n",
    "    df = bureau\n",
    "\n",
    "    agg_exprs = [\n",
    "        Fmax(\"credit_day_overdue\").alias(\"bureau_credit_day_overdue_max\"),\n",
    "        avg(\"credit_day_overdue\").alias(\"bureau_credit_day_overdue_mean\"),\n",
    "        Fmax(when(col(\"credit_day_overdue\") > 0, 1).otherwise(0)).alias(\n",
    "            \"bureau_has_dpd_flag\"\n",
    "        ),\n",
    "        Fsum(when(col(\"credit_day_overdue\") >= 30, 1).otherwise(0)).alias(\n",
    "            \"bureau_dpd_30_count\"\n",
    "        ),\n",
    "        Fsum(when(col(\"credit_day_overdue\") >= 60, 1).otherwise(0)).alias(\n",
    "            \"bureau_dpd_60_count\"\n",
    "        ),\n",
    "        Fsum(when(col(\"credit_day_overdue\") >= 90, 1).otherwise(0)).alias(\n",
    "            \"bureau_dpd_90_count\"\n",
    "        ),\n",
    "        Fsum(\"cnt_credit_prolong\").alias(\"bureau_cnt_credit_prolong_sum\"),\n",
    "        Fmax(\"cnt_credit_prolong\").alias(\"bureau_cnt_credit_prolong_max\"),\n",
    "        avg(\"cnt_credit_prolong\").alias(\"bureau_cnt_credit_prolong_mean\"),\n",
    "        Fmax(when(col(\"cnt_credit_prolong\") > 0, 1).otherwise(0)).alias(\n",
    "            \"bureau_has_prolongation_flag\"\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    return df.groupBy(\"sk_id_curr\").agg(*agg_exprs)\n",
    "\n",
    "\n",
    "def bureau_currency_and_annuity_features(bureau: DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "    7. CURRENCY AND ANNUITY FEATURES\n",
    "    \"\"\"\n",
    "    df = bureau\n",
    "\n",
    "    agg_exprs = [\n",
    "        F.countDistinct(\"credit_currency\").alias(\"bureau_currency_variety\"),\n",
    "        Fmax(when(col(\"credit_currency\") != \"currency 1\", 1).otherwise(0)).alias(\n",
    "            \"bureau_foreign_currency_flag\"\n",
    "        ),\n",
    "        Fsum(\"amt_annuity\").alias(\"bureau_amt_annuity_total\"),\n",
    "        avg(\"amt_annuity\").alias(\"bureau_amt_annuity_mean\"),\n",
    "        Fmax(\"amt_annuity\").alias(\"bureau_amt_annuity_max\"),\n",
    "    ]\n",
    "\n",
    "    return df.groupBy(\"sk_id_curr\").agg(*agg_exprs)\n",
    "\n",
    "\n",
    "def bureau_cross_table_ratio_features(bureau: DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "    8. CROSS-TABLE RATIO FEATURES: Utilization ratios by credit type and active/closed debt ratios\n",
    "    \"\"\"\n",
    "    df = bureau\n",
    "\n",
    "    # Group by sk_id_curr and credit_type for sums needed\n",
    "    agg_by_type = df.groupBy(\"sk_id_curr\", \"credit_type\").agg(\n",
    "        Fsum(\"amt_credit_sum_debt\").alias(\"sum_debt\"),\n",
    "        Fsum(\"amt_credit_sum_limit\").alias(\"sum_limit\"),\n",
    "        Fsum(\"amt_credit_sum\").alias(\"sum_credit\"),\n",
    "        Fsum(\n",
    "            when(\n",
    "                col(\"credit_active\") == \"Active\", col(\"amt_credit_sum_debt\")\n",
    "            ).otherwise(0)\n",
    "        ).alias(\"active_debt\"),\n",
    "    )\n",
    "\n",
    "    # Pivot utilization ratios for credit card and mortgage types\n",
    "    credit_card = agg_by_type.filter(col(\"credit_type\") == \"Credit card\").select(\n",
    "        \"sk_id_curr\",\n",
    "        (col(\"sum_debt\") / col(\"sum_limit\")).alias(\"bureau_cc_utilization_ratio\"),\n",
    "    )\n",
    "\n",
    "    mortgage = agg_by_type.filter(col(\"credit_type\") == \"Mortgage\").select(\n",
    "        \"sk_id_curr\",\n",
    "        (col(\"sum_debt\") / col(\"sum_credit\")).alias(\"bureau_mortgage_utilization\"),\n",
    "    )\n",
    "\n",
    "    # Sum total debt and active debt per sk_id_curr for active debt ratio\n",
    "    debt_totals = (\n",
    "        df.groupBy(\"sk_id_curr\")\n",
    "        .agg(\n",
    "            Fsum(\"amt_credit_sum_debt\").alias(\"total_debt\"),\n",
    "            Fsum(\n",
    "                when(\n",
    "                    col(\"credit_active\") == \"Active\", col(\"amt_credit_sum_debt\")\n",
    "                ).otherwise(0)\n",
    "            ).alias(\"active_debt_sum\"),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"bureau_active_debt_ratio\", col(\"active_debt_sum\") / col(\"total_debt\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Closed early ratio: count closed early credits / total credits\n",
    "    closed_early = (\n",
    "        df.withColumn(\n",
    "            \"closed_early_flag\",\n",
    "            when(\n",
    "                (col(\"credit_active\") == \"Closed\")\n",
    "                & (col(\"days_enddate_fact\") < col(\"days_credit_enddate\")),\n",
    "                1,\n",
    "            ).otherwise(0),\n",
    "        )\n",
    "        .groupBy(\"sk_id_curr\")\n",
    "        .agg(\n",
    "            (Fsum(\"closed_early_flag\") / count(\"sk_id_bureau\")).alias(\n",
    "                \"bureau_closed_early_ratio\"\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Join all cross-table ratios\n",
    "    from functools import reduce\n",
    "\n",
    "    dfs = [\n",
    "        credit_card,\n",
    "        mortgage,\n",
    "        debt_totals.select(\"sk_id_curr\", \"bureau_active_debt_ratio\"),\n",
    "        closed_early,\n",
    "    ]\n",
    "\n",
    "    df_final = reduce(\n",
    "        lambda left, right: left.join(right, on=\"sk_id_curr\", how=\"outer\"), dfs\n",
    "    )\n",
    "\n",
    "    return df_final.fillna(0)  # Fill nulls from joins with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f96125",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_counts_df = bureau_basic_counts_features(bureau_df)\n",
    "amount_based_df = bureau_amount_based_features(bureau_df)\n",
    "time_based_df = bureau_time_based_features(bureau_df)\n",
    "delinquency_df = bureau_delinquency_features(bureau_df)\n",
    "currency_annuity_df = bureau_currency_and_annuity_features(bureau_df)\n",
    "balance_df = bureau_balance_features(bureau_balance_df, bureau_df)\n",
    "cross_table_df = bureau_cross_table_ratio_features(bureau_df)\n",
    "\n",
    "final_df = (\n",
    "    basic_counts_df.join(amount_based_df, \"sk_id_curr\", \"left\")\n",
    "    .join(time_based_df, \"sk_id_curr\", \"left\")\n",
    "    .join(delinquency_df, \"sk_id_curr\", \"left\")\n",
    "    .join(currency_annuity_df, \"sk_id_curr\", \"left\")\n",
    "    .join(balance_df, \"sk_id_curr\", \"left\")\n",
    "    .join(cross_table_df, \"sk_id_curr\", \"left\")\n",
    ")\n",
    "\n",
    "final_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4993c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a16a24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb8c556",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5e6f68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae03ecd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5673a22d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490142b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
